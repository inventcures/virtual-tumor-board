% ============================================================================
% COMPREHENSIVE BIBLIOGRAPHY: Agentic Virtual Tumor Boards
% Multi-Agent AI Systems for Oncology Decision Support
% Compiled January 2026
% ============================================================================

% ============================================================================
% SECTION 1: MULTI-AGENT MEDICAL AI SYSTEMS
% ============================================================================

@article{tang2023medagents,
  title={{MedAgents}: Large Language Models as Collaborators for Zero-shot Medical Reasoning},
  author={Tang, Xiangru and Zou, Anni and Zhang, Zhuosheng and Li, Ziming and Zhao, Yilun and Zhang, Xingyao and Cohan, Arman and Gerstein, Mark},
  journal={arXiv preprint arXiv:2311.10537},
  year={2023},
  note={Multi-disciplinary collaboration framework achieving improved performance on 9 medical QA datasets including MedQA, MedMCQA, and PubMedQA through role-playing expert discussions}
}

@article{tang2025medagentsbench,
  title={{MedAgentsBench}: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning},
  author={Tang, Xiangru and Shao, Daniel and Sohn, Jiwoong and Chen, Jiapeng and Zhang, Jiayi and Xiang, Jinyu and Wu, Fang and Zhao, Yilun and Wu, Chenglin and Shi, Wenqi and Cohan, Arman and Gerstein, Mark},
  journal={arXiv preprint arXiv:2503.07459},
  year={2025},
  note={Benchmark for complex medical reasoning; DeepSeek R1 and OpenAI o3 show exceptional performance on multi-step clinical reasoning tasks}
}

@article{wang2025medagentpro,
  title={{MedAgent-Pro}: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow},
  author={Wang, Ziyue and Wu, Junde and Cai, Linghan and Low, Chang Han and Yang, Xihong and Li, Qiaxuan and Jin, Yueming},
  journal={arXiv preprint arXiv:2503.18968},
  year={2025},
  note={Hierarchical diagnostic structure with RAG-based agent for guideline retrieval; demonstrates evidence-based reasoning across anatomical regions and modalities}
}

@article{schmidgall2024agentclinic,
  title={{AgentClinic}: A Multimodal Agent Benchmark to Evaluate {LLMs} in Simulated Clinical Environments},
  author={Schmidgall, Samuel and Ziaei, Rojin and Harris, Carl and Reis, Eduardo and Jopling, Jeffrey and Moor, Michael},
  journal={arXiv preprint arXiv:2405.07960},
  year={2024},
  note={Multimodal benchmark for sequential clinical decision-making across 9 specialties and 7 languages; Claude-3.5 outperforms other LLM backbones; diagnostic accuracy drops to below 10\% of MedQA accuracy in sequential format}
}

@article{wang2024colacare,
  title={{ColaCare}: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration},
  author={Wang, Zixiang and Zhu, Yinghao and Zhao, Huiya and Zheng, Xiaochen and Sui, Dehao and Wang, Tianlong and Tang, Wen and Wang, Yasha and Harrison, Ewen and Pan, Chengwei and Gao, Junyi and Ma, Liantao},
  journal={ACM TheWebConf 2025},
  year={2025},
  doi={10.1145/3696410.3714877},
  note={MDT-inspired DoctorAgents and MetaAgent collaboration with RAG module using Merck Manual guidelines; superior mortality and readmission prediction}
}

@article{feng2025ucagents,
  title={{UCAgents}: Unidirectional Convergence for Visual Evidence Anchored Multi-Agent Medical Decision-Making},
  author={Feng, Qianhan and Huang, Zhongzhen and Zhu, Yakun and Zhang, Xiaofan and Dou, Qi},
  journal={arXiv preprint arXiv:2512.02485},
  year={2025},
  note={Hierarchical multi-agent framework achieving 71.3\% on PathVQA (+6.0\% over SOTA) with 87.7\% lower token cost through structured evidence auditing}
}

@article{blondeel2025hao,
  title={Demo: Healthcare Agent Orchestrator ({HAO}) for Patient Summarization in Molecular Tumor Boards},
  author={Blondeel, Matthias and Codella, Noel and Preston, Sam and Qiu, Hao and Schettini, Leonardo and Tuan, Frank and Yim, Wen-wai and Saligrama, Smitha and {\"O}z, Mert and Jain, Shrey and Lungren, Matthew P and Osborne, Thomas},
  journal={arXiv preprint arXiv:2509.06602},
  year={2025},
  note={LLM-driven multi-agent workflow for MTB patient summaries; TBFact framework achieves 94\% capture of high-importance information}
}

@article{palepu2024amie_oncology,
  title={Exploring Large Language Models for Specialist-level Oncology Care},
  author={Palepu, Anil and Dhillon, Vikram and Niravath, Polly and Weng, Wei-Hung and Prasad, Preethi and Saab, Khaled and Tanno, Ryutaro and Cheng, Yong and Mai, Hanh and Burns, Ethan and others},
  journal={arXiv preprint arXiv:2411.03395},
  year={2024},
  note={AMIE system evaluated on 50 breast cancer vignettes for MDT decision-making; outperforms trainees/fellows but inferior to attending oncologists}
}

% ============================================================================
% SECTION 2: MEDICAL AI SAFETY AND HALLUCINATION PREVENTION
% ============================================================================

@article{peng2026sycoeval,
  title={{SycoEval-EM}: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care},
  author={Peng, Dongshen and Wang, Yi and Preiksaitis, Carl and Rose, Christian},
  journal={arXiv preprint arXiv:2601.16529},
  year={2026},
  note={Multi-agent simulation evaluating 20 LLMs across 1,875 emergency encounters; acquiescence rates 0-100\%; imaging requests (38.8\%) more vulnerable than opioid prescriptions (25.0\%)}
}

@article{garcia2025check,
  title={{CHECK}: Continuous Hallucination Detection and Elimination for Trustworthy AI in Medicine},
  author={Garcia-Fernandez, Carlos and Felipe, Luis and Shotande, Monique and Zitu, Muntasir and Tripathi, Aakash and Rasool, Ghulam and El Naqa, Issam and Rudrapatna, Vivek and Valdes, Gilmer},
  journal={arXiv preprint arXiv:2506.11129},
  year={2025},
  note={Continuous-learning framework reducing LLaMA3.3-70B hallucination from 31\% to 0.3\%; achieves 92.1\% USMLE passing rate with GPT-4o refinement}
}

@article{pan2025das_redteam,
  title={Beyond Benchmarks: Dynamic, Automatic And Systematic Red-Teaming Agents For Trustworthy Medical Language Models},
  author={Pan, Jiazhen and Jian, Bailiang and Hager, Paul and Zhang, Yundi and Liu, Che and Jungmann, Friedrike and Li, Hongwei Bran and You, Chenyu and Wu, Junde and others},
  journal={arXiv preprint arXiv:2508.00923},
  year={2025},
  note={DAS red-teaming on 15 LLMs reveals 94\% failure on dynamic robustness tests despite >80\% MedQA accuracy; 86\% privacy leak rates, 81\% cognitive bias priming success, >66\% hallucination rates}
}

@article{das2025hallucinations_clinical,
  title={Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models},
  author={Das, Anindya Bijoy and Ahmed, Shibbir and Sakib, Shahnewaz Karim},
  journal={arXiv preprint arXiv:2504.19061},
  year={2025},
  note={Assessment of LLMs (Qwen2.5, DeepSeek-v2) on discharge report extraction; good at admission reasons but inconsistent for follow-up recommendations}
}

@article{vladika2025atomic_fact,
  title={Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented {LLMs}},
  author={Vladika, Juraj and Domres, Annika and Nguyen, Mai and Moser, Rebecca and Nano, Jana and Busch, Felix and Adams, Lisa C and Bressem, Keno K and Bernhardt, Denise and Combs, Stephanie E and Borm, Kai J and Matthes, Florian and Peeken, Jan C},
  journal={arXiv preprint arXiv:2505.24830},
  year={2025},
  note={Atomic fact-checking achieving 40\% overall answer improvement and 50\% hallucination detection; multi-reader expert validation confirms factual accuracy gains}
}

@article{javadi2025contradictory_rag,
  title={When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation in Healthcare},
  author={Javadi, Saeedeh and Mirabi, Sara and Gangar, Manan and Ofoghi, Bahadorreza},
  journal={arXiv preprint arXiv:2511.06668},
  year={2025},
  note={Investigation of 5 LLMs on TGA medicine documents; contradictions between similar abstracts degrade performance and reduce factual accuracy}
}

% ============================================================================
% SECTION 3: MULTIMODAL MEDICAL AI
% ============================================================================

@article{sellergren2025medgemma,
  title={{MedGemma} Technical Report},
  author={Sellergren, Andrew and Kazemzadeh, Sahar and Jaroensri, Tiam and Kiraly, Atilla and Traverse, Madeleine and Kohlberger, Timo and Xu, Shawn and Jamil, Fayaz and Hughes, C{\'\i}an and Lau, Charles and others},
  journal={arXiv preprint arXiv:2507.05201},
  year={2025},
  note={Medical VLM collection based on Gemma 3; 2.6-10\% improvement on medical multimodal QA, 15.5-18.1\% on CXR classification, 10.8\% on agentic evaluations; 50\% error reduction in EHR retrieval after fine-tuning}
}

@article{messina2026cure,
  title={{CURE}: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation},
  author={Messina, Pablo and Villa, Andr{\'e}s and Alc{\'a}zar, Juan Le{\'o}n and S{\'a}nchez, Karen and Hinojosa, Carlos and Parra, Denis and Soto, {\'A}lvaro and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2601.15408},
  year={2026},
  note={Error-aware curriculum learning on MedGemma achieving +0.37 IoU grounding, +0.188 CXRFEScore, 18.6\% hallucination reduction}
}

@article{prottasha2025medgemma_gpt4,
  title={{MedGemma} vs {GPT-4}: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images},
  author={Prottasha, Md Sazzadul Islam and Rafi, Nabil Walid},
  journal={Journal of Machine Learning and Deep Learning},
  year={2025},
  note={MedGemma-4b-it achieves 80.37\% mean accuracy vs 69.58\% for GPT-4; higher sensitivity in cancer and pneumonia detection}
}

@article{gosai2025pathology_localization,
  title={Beyond Diagnosis: Evaluating Multimodal {LLMs} for Pathology Localization in Chest Radiographs},
  author={Gosai, Advait and Kavishwar, Arun and McNamara, Stephanie L and Samineni, Soujanya and Umeton, Renato and Chowdhury, Alexander and Lotter, William},
  journal={ML4H 2025},
  year={2025},
  note={GPT-5 achieves 49.7\% localization accuracy on CheXlocalize; error analysis shows anatomically plausible predictions even when not precisely localized}
}

@article{kartasalo2025prostate_pathology,
  title={Validation of Diagnostic Artificial Intelligence Models for Prostate Pathology in a Middle Eastern Cohort},
  author={Muhammad Ali, Peshawa J and Vincent, Navin and Abdulla, Saman S and Fadhl, Han N Mohammed and Blilie, Anders and Szolnoky, Kelvin and others},
  journal={arXiv preprint arXiv:2512.17499},
  year={2025},
  note={First Middle East external validation for prostate AI; pathologist-level concordance (kappa 0.801 vs 0.799); compact scanners enable cost-effective AI adoption in resource-limited settings}
}

@article{yan2025pathorchestra,
  title={{PathOrchestra}: A Comprehensive Foundation Model for Computational Pathology with Over 100 Diverse Clinical-Grade Tasks},
  author={Yan, Fang and Wu, Jianfeng and Li, Jiawen and Wang, Wei and Lu, Jiaxuan and Chen, Wen and Gao, Zizhao and Li, Jianan and Yan, Hong and others},
  journal={arXiv preprint arXiv:2503.24345},
  year={2025},
  note={Foundation model trained on 300K slides achieving >95\% accuracy on 47 tasks; first to generate structured reports for colorectal cancer and lymphoma}
}

@article{contino2023iodeep,
  title={{IODeep}: An {IOD} for the Introduction of Deep Learning in the {DICOM} Standard},
  author={Contino, Salvatore and Cruciata, Luca and Gambino, Orazio and Pirrone, Roberto},
  journal={Computer Methods and Programs in Biomedicine},
  volume={248},
  year={2024},
  doi={10.1016/j.cmpb.2024.108113},
  note={DICOM Information Object Definition for storing trained DNN architectures and weights, enabling AI model integration in radiology infrastructure}
}

% ============================================================================
% SECTION 4: TUMOR BOARDS AND CLINICAL DECISION SUPPORT
% ============================================================================

@article{zhang2025multiagent_gi_oncology,
  title={Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology},
  author={Zhang, Rongzhao and Wang, Junqiao and Yang, Shuyun and Bian, Mouxiao and Zhang, Chihao and Wang, Dongyang and Yan, Qiujuan and Zhong, Yun and Bai, Yuwei and others},
  journal={arXiv preprint arXiv:2512.08674},
  year={2025},
  note={Hierarchical multi-agent MDT simulation achieving 4.60/5.00 expert score; substantial improvements in reasoning logic and medical accuracy over monolithic baselines}
}

@article{liu2026ai_mdt,
  title={{AI-MDT}: An Automatic and Intelligent Multidisciplinary Team Consultations Platform for Lung Cancer Diagnosis},
  author={Liu, Y and Wang, F and Wang, P and Zhou, Z and Wang, H and Li, J and Qiu, Y and Wang, H and Miao, S},
  journal={Journal of Cancer Research and Clinical Oncology},
  volume={152},
  number={1},
  pages={32},
  year={2026},
  doi={10.1007/s00432-025-06413-5},
  note={Automated MDT platform for pulmonary nodule management addressing efficiency and evidence-based decision support challenges}
}

@article{kenaston2025cognitive_bias,
  title={Cognitive bias in {LLM} reasoning compromises interpretation of clinical oncology notes},
  author={Kenaston, Matthew W and Ayub, Umair and Parmar, Mihir and Anjum, Muhammad Umair and Naqvi, Syed Arsalan Ahmed and Kumar, Priya and Rawal, Samarth and Chaudhuri, Aadel A and others},
  journal={arXiv preprint arXiv:2511.20680},
  year={2025},
  note={Hierarchical taxonomy of GPT-4 reasoning errors in oncology notes; 23\% reasoning error rate with confirmation and anchoring bias most common; reasoning failures associated with guideline-discordant recommendations}
}

@article{hemadri2025oncoreason,
  title={{OncoReason}: Structuring Clinical Reasoning in {LLMs} for Robust and Interpretable Survival Prediction},
  author={Hemadri, Raghu Vamshi and Guruju, Geetha Krishna and Topollai, Kristi and Choromanska, Anna Ewa},
  journal={arXiv preprint arXiv:2510.17532},
  year={2025},
  note={Multi-task framework with GRPO achieving SOTA on MSK-CHORD survival prediction; CoT improves F1 by +6.0 and reduces MAE by 12\%}
}

@article{li2025clicare,
  title={{CliCARE}: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records},
  author={Li, Dongchen and Liang, Jitao and Li, Wei and Wang, Xiaoyu and Cao, Longbing and Yu, Kun},
  journal={AAAI 2026},
  year={2025},
  note={Framework transforming EHRs into Temporal Knowledge Graphs aligned with guideline KGs; significantly outperforms long-context LLMs and KG-RAG baselines on Chinese and MIMIC-IV datasets}
}

% ============================================================================
% SECTION 5: GLOBAL HEALTH AND HEALTHCARE ACCESS
% ============================================================================

@article{menon2026cancer_disparities_saarc,
  title={Intersectionality of Cancer Disparities in South Asia},
  author={Menon, TP and Mathew, A and Iyengar, P and Gyawali, B and Pramesh, CS and Dee, EC},
  journal={Lancet Global Health},
  volume={14},
  number={2},
  pages={e272--e280},
  year={2026},
  doi={10.1016/S2214-109X(25)00444-9},
  note={SAARC region (2 billion+ population) cancer burden shaped by heterogeneity in risk, access, and outcomes; large proportions living in poverty}
}

@article{bajaj2025surgical_inequity,
  title={Global Inequities in Accessing Cancer Surgical Care and Strategies to Address Them},
  author={Bajaj, V and Vuthaluru, S and Leiphrakpam, PD and Shukla, S and Nusrath, S and Hariharan, N and Rao, TS and Are, C},
  journal={Indian Journal of Surgical Oncology},
  volume={16},
  number={6},
  pages={1423--1428},
  year={2025},
  doi={10.1007/s13193-025-02189-9},
  note={Comprehensive review of global inequities in cancer surgical care access with strategies for improvement}
}

@article{pitiyarachchi2025ngs_asia_pacific,
  title={Utilization, Reimbursement, and Barriers to Accessing Sequencing Tests for Cancer Care in the Asia-Pacific Region},
  author={Pitiyarachchi, O and Tan, AC and Thambamroong, T and Velasco Jr, R and Uehara, Y and Lee, D and Kao, HF and Agarwala, V and Lim, YN and Priantono, D and Ahani, AR and Win, KZ and Kim, YS and Yoo, C},
  journal={Cancer Research and Treatment},
  year={2025},
  doi={10.4143/crt.2025.896},
  note={KSMO study of NGS utilization across Asia-Pacific revealing healthcare diversity and economic disparity in precision oncology access}
}

@article{francis2025oral_cancer_lmics,
  title={Oral Cancer Disparities in Low- and Middle-Income Countries: A Global Health Equity Perspective on Prevention, Early Detection, and Treatment Access},
  author={Francis, DL and Pape Reddy, SS},
  journal={Annals of Global Health},
  volume={91},
  number={1},
  pages={81},
  year={2025},
  doi={10.5334/aogh.5003},
  note={Global health disparities review emphasizing prevention, screening, and treatment access gaps in LMICs}
}

@article{yadav2025bridge_breast_cancer,
  title={{BRIDGEing} the Gap: Impact of a Short Virtual Course on Delivering Global-Standard Breast Cancer Care in Low-Resource Settings},
  author={Yadav, SK and Garg, G and Baderiya, D and others},
  journal={World Journal of Surgery},
  year={2025},
  doi={10.1002/wjs.70195},
  note={Virtual training program for guideline-concordant breast cancer care in LMICs addressing limited access to advanced diagnostics}
}

@article{debnath2025cancer_india_tertiary,
  title={Epidemiological Profile of Patients with Malignant Neoplasm Admitted to a Tertiary Care Center in India: A Retrospective Cross-sectional Study},
  author={Debnath, S and Pal, P and Singh, AK and Mishra, S and Rajotiya, S and Ghosh, M and Nakash, P and Kumar, S and Singh, R and Sharma, G and Singh, M and Nathiya, D and Tomar, BS},
  journal={Frontiers in Oncology},
  volume={15},
  pages={1636807},
  year={2025},
  doi={10.3389/fonc.2025.1636807},
  note={Urban-rural cancer disparities in India; rural patients experience greater burden due to delayed diagnosis and limited access}
}

@article{parikh2025geriatric_oncology_asia,
  title={Setting Up Geriatric Oncology Clinical Services: Asian Geriatric Oncology Society Guidelines 2025 (Part 1)},
  author={Parikh, PM and Banerjee, J and Rajendranath, R and Prem, NN and Soni, N and Tilak, TVSVGK and {Asian Geriatric Oncology Society}},
  journal={South Asian Journal of Cancer},
  volume={14},
  number={2},
  pages={135--142},
  year={2025},
  doi={10.1055/s-0045-1806763},
  note={Asian Geriatric Oncology Society guidelines for developing geriatric oncology services including MDT components}
}

% ============================================================================
% SECTION 6: RAG AND TECHNICAL APPROACHES
% ============================================================================

@article{zhu2026mrag_benchmark,
  title={{MRAG}: Benchmarking Retrieval-Augmented Generation for Bio-medicine},
  author={Zhu, Wei},
  journal={arXiv preprint arXiv:2601.16503},
  year={2026},
  note={Comprehensive RAG benchmark covering English and Chinese medical QA with Wikipedia and PubMed corpus; RAG enhances reliability across all tasks}
}

@article{jang2026medtutor,
  title={{MedTutor}: A Retrieval-Augmented {LLM} System for Case-Based Medical Education},
  author={Jang, Dongsuk and Shangguan, Ziyao and Tegtmeyer, Kyle and Gupta, Anurag and Czerminski, Jan and Chheang, Sophie and Cohan, Arman},
  journal={EMNLP 2025 System Demonstrations},
  pages={319--353},
  year={2026},
  doi={10.18653/v1/2025.emnlp-demos.24},
  note={RAG system generating educational content from clinical case reports; hybrid retrieval from textbooks and literature with radiologist validation}
}

@article{ji2026medragchecker,
  title={{MedRAGChecker}: Claim-Level Verification for Biomedical Retrieval-Augmented Generation},
  author={Ji, Yuelyu and Kwak, Min Gu and Zhang, Hang and Wu, Xizhi and Li, Chenyu and Wang, Yanshan},
  journal={arXiv preprint arXiv:2601.06519},
  year={2026},
  note={Claim-level verification combining NLI with biomedical KG consistency; ensemble verifier with reliability weighting achieves 0.95-0.96 AUC on medical benchmarks}
}

@article{ryan2026selfmedrag,
  title={{Self-MedRAG}: A Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering},
  author={Ryan, Jessica and Gumilang, Alexander I and Wiliam, Robert and Suhartono, Derwin},
  journal={arXiv preprint arXiv:2601.04531},
  year={2026},
  note={Hybrid BM25+Contriever RAG with self-reflection via NLI; improves MedQA from 80\% to 83.33\% and PubMedQA from 69.10\% to 79.82\%}
}

@article{hang2025trumorgpt,
  title={{TrumorGPT}: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking},
  author={Hang, Ching Nam and Yu, Pei-Duo and Tan, Chee Wei},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2025},
  doi={10.1109/TAI.2025.3567369},
  note={GraphRAG for health misinformation fact-checking using semantic health knowledge graphs; superior performance across healthcare datasets}
}

@article{li2025garmle,
  title={Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines},
  author={Li, Wenhao and Zhang, Hongkuan and Zhang, Hongwei and Li, Zhengxu and Dong, Zengjie and Chen, Yafan and Bidargaddi, Niranjan and Liu, Hong},
  journal={Journal of Biomedical and Health Informatics},
  year={2025},
  note={GARMLE-G framework grounding LLMs in CPGs; hallucination-free outputs through direct guideline retrieval without model-generated text}
}

% ============================================================================
% SECTION 7: CHAIN-OF-THOUGHT AND CLINICAL REASONING
% ============================================================================

@article{liu2025cope_stroke,
  title={{COPE}: Chain-of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes},
  author={Liu, Yongkai and Feng, Helena and Jiang, Bin and Wang, Yixin and Wintermark, Max and Liebeskind, David S and Moseley, Michael and Lansberg, Maarten and Albers, Gregory and Heit, Jeremy and Zaharchuk, Greg},
  journal={arXiv preprint arXiv:2512.02499},
  year={2025},
  note={Two-step CoT framework for 90-day mRS prediction achieving MAE 1.01 and 74.4\% accuracy within +/-1 point; comparable to GPT-4.1}
}

@article{jiang2026m3cotbench,
  title={{M3CoTBench}: Benchmark Chain-of-Thought of {MLLMs} in Medical Image Understanding},
  author={Jiang, Juntao and Zhang, Jiangning and Bi, Yali and Bai, Jinsheng and Liu, Weixuan and Jin, Weiwei and Xue, Zhucun and Liu, Yong and Hu, Xiaobin and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2601.08758},
  year={2026},
  note={First benchmark for CoT in medical imaging across 24 exam types and 13 tasks; evaluates correctness, efficiency, impact, and consistency of reasoning}
}

@article{ye2026petbench,
  title={Unveiling and Bridging the Functional Perception Gap in {MLLMs}: Atomic Visual Alignment and Hierarchical Evaluation via {PET-Bench}},
  author={Ye, Zanting and Niu, Xiaolong and Wu, Xuanbin and Han, Xu and Liu, Shengyuan and Hao, Jing and Peng, Zhihao and Sun, Hao and Lv, Jieqin and Wang, Fanghu and others},
  journal={arXiv preprint arXiv:2601.02737},
  year={2026},
  note={CoT hallucination trap identified in PET imaging; Atomic Visual Alignment improves diagnostic accuracy by 14.83\% by enforcing perception before reasoning}
}

@article{tripathi2025lsp,
  title={Logic Sketch Prompting ({LSP}): A Deterministic and Interpretable Prompting Method},
  author={Tripathi, Satvik},
  journal={arXiv preprint arXiv:2512.22258},
  year={2025},
  note={Rule-based prompting achieving 0.83-0.89 F1 on pharmacologic compliance; outperforms zero-shot and CoT prompting across Gemma 2, Mistral, Llama 3}
}

@article{wei2025epiqal,
  title={{EpiQAL}: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning},
  author={Wei, Mingyang and Min, Dehai and Liu, Zewen and Xie, Yuzhang and Wu, Guanchen and Yang, Carl and Lau, Max S Y and He, Qi and Cheng, Lu and Jin, Wei},
  journal={arXiv preprint arXiv:2601.03471},
  year={2026},
  note={Diagnostic benchmark for epidemiological reasoning; CoT benefits multi-step inference but yields mixed results elsewhere}
}

% ============================================================================
% SECTION 8: HUMAN-IN-THE-LOOP SYSTEMS
% ============================================================================

@article{nusrat2025sage_radiosurgery,
  title={Automated Stereotactic Radiosurgery Planning using a Human-in-the-Loop Reasoning Large Language Model Agent},
  author={Nusrat, Humza and Francisco, Luke and Luo, Bing and Bagher-Ebadian, Hassan and Kim, Joshua and Chin-Snyder, Karen and Siddiqui, Salim and Shah, Mira and Mellon, Eric and Ghassemi, Mohammad and Doemer, Anthony and Movsas, Benjamin and Thind, Kundan},
  journal={arXiv preprint arXiv:2512.20586},
  year={2025},
  note={SAGE agent for SRS planning achieving comparable dosimetry to human planners; reasoning model shows 457 constraint verifications and 609 trade-off deliberations}
}

@article{pellegrini2025radialog,
  title={{RaDialog}: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance},
  author={Pellegrini, Chantal and {\"O}zsoy, Ege and Busam, Benjamin and Navab, Nassir and Keicher, Matthias},
  journal={MIDL 2025},
  year={2025},
  note={Human-in-the-loop radiology assistant integrating visual features with LLM; achieves SOTA clinical correctness in report generation and interactive correction}
}

@article{wang2024copilotcad,
  title={{CopilotCAD}: Empowering Radiologists with Report Completion Models and Quantitative Evidence from Medical Image Foundation Models},
  author={Wang, Sheng and Du, Tianming and Fischer, Katherine and Tasian, Gregory E and Ziemba, Justin and Garratt, Joanie M and Sagreiya, Hersh and Fan, Yong},
  journal={arXiv preprint arXiv:2404.07424},
  year={2024},
  note={AI co-pilot combining LLMs with medical image analysis for radiologist workflow support; improves precision and reduces burnout}
}

@article{ridzuan2024hulp,
  title={{HuLP}: Human-in-the-Loop for Prognosis},
  author={Ridzuan, Muhammad and Kassem, Mai and Saeed, Numan and Sobirov, Ikboljon and Yaqub, Mohammad},
  journal={arXiv preprint arXiv:2403.13078},
  year={2024},
  note={Framework enabling clinician intervention for prognostic model correction; addresses missing covariates through neural network imputation aligned with clinician workflows}
}

@article{spiegler2025samira,
  title={Towards User-Centered Interactive Medical Image Segmentation in {VR} with an Assistive {AI} Agent},
  author={Spiegler, Pascal and Harirpoush, Arash and Xiao, Yiming},
  journal={arXiv preprint arXiv:2505.07214},
  year={2025},
  note={SAMIRA conversational AI agent for medical VR achieving SUS=90.0; compares controller, head, and eye-tracking input modes for human-in-the-loop segmentation}
}

% ============================================================================
% SECTION 9: EVALUATOR-OPTIMIZER PATTERNS
% ============================================================================

@article{fierro2025weight_steering,
  title={Steering Language Models with Weight Arithmetic},
  author={Fierro, Constanza and Roger, Fabien},
  journal={arXiv preprint arXiv:2511.05408},
  year={2025},
  note={Contrastive weight steering for sycophancy mitigation; achieves stronger OOD behavioral control than activation steering while preserving capabilities}
}

@article{batzner2025sycophancy_hitl,
  title={Sycophancy Claims about Language Models: The Missing Human-in-the-Loop},
  author={Batzner, Jan and Stocker, Volker and Schmid, Stefan and Kasneci, Gjergji},
  journal={NeurIPS 2025 Workshop on LLM Evaluation},
  year={2025},
  note={Review of sycophancy measurement methodologies; identifies five core operationalizations and notes lack of human perception evaluation}
}

@article{celebi2025parrot,
  title={{PARROT}: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for {LLMs}},
  author={{\c{C}}elebi, Yusuf and Ezerceli, {\"O}zay and El Hussieni, Mahmoud},
  journal={arXiv preprint arXiv:2511.17220},
  year={2025},
  note={Benchmark on 22 models across 1,302 MMLU questions; GPT-5 shows 4\% follow rate while older models show severe collapse (GPT-4: 80\%, Qwen 2.5-1.5B: 94\%)}
}

@article{petrov2025brokenmath,
  title={{BrokenMath}: A Benchmark for Sycophancy in Theorem Proving with {LLMs}},
  author={Petrov, Ivo and Dekoninck, Jasper and Vechev, Martin},
  journal={arXiv preprint arXiv:2510.04721},
  year={2025},
  note={First theorem proving sycophancy benchmark from 2025 competition problems; GPT-5 produces sycophantic answers 29\% of time; expert review validation}
}

@article{sadhu2025hpo,
  title={Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable {AI} Tutoring},
  author={Sadhu, Saisab and Dhor, Ashim},
  journal={AAAI 2026 EGSAI},
  year={2025},
  note={Dialectical multi-agent framework achieving 0.845 Macro F1 with 8B model (outperforming GPT-4o at 0.812) using 20x fewer parameters}
}

% ============================================================================
% SECTION 10: FOUNDATIONAL AND SEMINAL WORKS
% ============================================================================

@article{singhal2023med_palm,
  title={Large Language Models Encode Clinical Knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023},
  doi={10.1038/s41586-023-06291-2},
  note={Med-PaLM achieves expert-level performance on USMLE; foundational work demonstrating clinical knowledge encoding in LLMs}
}

@article{tu2024conversational_diagnostic,
  title={Towards Conversational Diagnostic {AI}},
  author={Tu, Tao and Palepu, Anil and Schaekermann, Mike and Saab, Khaled and Freyberg, Jan and Tanno, Ryutaro and Wang, Amy and Li, Brenna and Amin, Mohamed and Tomasev, Nenad and others},
  journal={arXiv preprint arXiv:2401.05654},
  year={2024},
  note={AMIE diagnostic AI system demonstrating multi-turn conversational diagnostic capabilities}
}

@article{nori2023capabilities_gpt4,
  title={Capabilities of {GPT-4} on Medical Challenge Problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023},
  note={GPT-4 achieves 86.7\% on USMLE without specialized prompting; establishes baseline for medical LLM evaluation}
}

@article{thirunavukarasu2023large_language_medicine,
  title={Large Language Models in Medicine},
  author={Thirunavukarasu, Arun James and Ting, Daniel Shu Wei and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature Medicine},
  volume={29},
  pages={1930--1940},
  year={2023},
  doi={10.1038/s41591-023-02448-8},
  note={Comprehensive review of LLM applications in medicine; discusses opportunities and challenges}
}

@article{beam2023challenges_medical_ai,
  title={Challenges to the Reproducibility of Machine Learning Models in Health Care},
  author={Beam, Andrew L and Manrai, Arjun K and Ghassemi, Marzyeh},
  journal={JAMA},
  volume={329},
  number={5},
  pages={379--380},
  year={2023},
  doi={10.1001/jama.2023.0005},
  note={Discussion of reproducibility challenges in medical AI deployment}
}

% ============================================================================
% END OF BIBLIOGRAPHY
% ============================================================================
